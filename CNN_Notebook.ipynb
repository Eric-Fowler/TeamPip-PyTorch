{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Data/data_train.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Programming\\School\\School Repos\\EEL5840 - Fundamentals of Machine Learning\\TeamPip-PyTorch\\CNN_Notebook.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Programming/School/School%20Repos/EEL5840%20-%20Fundamentals%20of%20Machine%20Learning/TeamPip-PyTorch/CNN_Notebook.ipynb#ch0000002?line=0'>1</a>\u001b[0m data_og \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39mData/data_train.npy\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39mT\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Programming/School/School%20Repos/EEL5840%20-%20Fundamentals%20of%20Machine%20Learning/TeamPip-PyTorch/CNN_Notebook.ipynb#ch0000002?line=1'>2</a>\u001b[0m labels_og \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mloadtxt(\u001b[39m'\u001b[39m\u001b[39mData/correct_labels.npy\u001b[39m\u001b[39m'\u001b[39m,delimiter\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Programming/School/School%20Repos/EEL5840%20-%20Fundamentals%20of%20Machine%20Learning/TeamPip-PyTorch/CNN_Notebook.ipynb#ch0000002?line=3'>4</a>\u001b[0m train_data, test_data, train_labels, test_labels \u001b[39m=\u001b[39m train_test_split(data_og, labels_og, test_size\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\hw\\lib\\site-packages\\numpy\\lib\\npyio.py:417\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Blade/Anaconda3/envs/hw/lib/site-packages/numpy/lib/npyio.py?line=414'>415</a>\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Blade/Anaconda3/envs/hw/lib/site-packages/numpy/lib/npyio.py?line=415'>416</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/Blade/Anaconda3/envs/hw/lib/site-packages/numpy/lib/npyio.py?line=416'>417</a>\u001b[0m     fid \u001b[39m=\u001b[39m stack\u001b[39m.\u001b[39menter_context(\u001b[39mopen\u001b[39;49m(os_fspath(file), \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[0;32m    <a href='file:///c%3A/Users/Blade/Anaconda3/envs/hw/lib/site-packages/numpy/lib/npyio.py?line=417'>418</a>\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Blade/Anaconda3/envs/hw/lib/site-packages/numpy/lib/npyio.py?line=419'>420</a>\u001b[0m \u001b[39m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Data/data_train.npy'"
     ]
    }
   ],
   "source": [
    "data_og = np.load('Data/data_train.npy').T\n",
    "labels_og = np.loadtxt('Data/correct_labels.npy',delimiter=',')\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data_og, labels_og, test_size=0.2, random_state=42)\n",
    "\n",
    "nimages = len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_and_labels(Dataset):\n",
    "    def __init__(self,data,labels,transform = None):\n",
    "        self.transform = transform\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    def __getitem__(self,index):\n",
    "        image = self.data[index,:]\n",
    "        image = image.reshape(300,300)\n",
    "        label = torch.tensor(int(self.labels[index]))\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return (image,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5376, 90000)\n",
      "5376\n",
      "4300\n",
      "1076\n"
     ]
    }
   ],
   "source": [
    "dataset = data_and_labels(train_data,train_labels,transform = transforms.ToTensor())\n",
    "print(np.shape(train_data))\n",
    "print(nimages)\n",
    "print(int(nimages*0.8))\n",
    "print(nimages-int(nimages*0.8))\n",
    "train_set,valid_set = torch.utils.data.random_split(dataset,[int(nimages*0.8),nimages-int(nimages*0.8)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_set,batch_size=20,shuffle=True,num_workers=2)\n",
    "test_loader = DataLoader(dataset=valid_set,batch_size=20,shuffle=True,num_workers=2)\n",
    "\n",
    "lr = 0.001\n",
    "momentum = 0.9\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conv1\n",
    "c1inputsize = 1 #greyscale\n",
    "c1outputsize = 3 #idk\n",
    "c1kernelsize = 5 #idk\n",
    "#pool1\n",
    "p1ks = 5 #kernel size\n",
    "p1s = p1ks #stride size\n",
    "#conv2\n",
    "c2is = c1outputsize\n",
    "c2os = 10\n",
    "c2ks = 5\n",
    "#fully connected 1\n",
    "fc1is = c2os*c1kernelsize*c2ks\n",
    "fc1os = 80\n",
    "#fully connected 2\n",
    "fc2is = fc1os\n",
    "fc2os = 40\n",
    "#fully connected 3\n",
    "fc3is = fc2os\n",
    "fc3os = 22\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(c1inputsize,c1outputsize,c1kernelsize),\n",
    "    nn.MaxPool2d(p1ks,p1s),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(c2is,c2os,c2ks),\n",
    "    nn.ReLU(),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(fc1is,fc1os),\n",
    "    nn.Linear(fc2is,fc2os),\n",
    "    nn.Linear(fc3is,fc3os)\n",
    ")\n",
    "model.to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(),lr=lr,momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "for epoch in range(1,num_epochs+1):\n",
    "    train_loss=0.0\n",
    "    valid_loss=0.0\n",
    "    model.train()\n",
    "    for image, label in train_loader:\n",
    "        image = image.cuda()\n",
    "        label = label.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        prediction=  model(image)\n",
    "        loss = loss_fn(prediction,label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss+=loss.item()*image.size(0)\n",
    "    model.eval()\n",
    "    for image,label in test_loader:\n",
    "        image = image.cuda()\n",
    "        label = label.cuda()\n",
    "        prediction = model(image)\n",
    "        loss = loss_fn(prediction,label)\n",
    "        valid_loss+=loss.item()*image.size(0)\n",
    "    train_loss = train_loss/len(train_loader.sampler)\n",
    "    valid_loss = valid_loss/len(test_loader.sampler)\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "\n",
    "    print('Epoch:{} Train Loss:{:.4f} valid Loss:{:.4f}'.format(epoch,train_loss,valid_loss))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "18b4a29b6ae822962b6086afb30b1194e645f804902d5e3c272cfb3fc91717af"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('hw')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
